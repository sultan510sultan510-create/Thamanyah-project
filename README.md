# 🎯 نظام بث تفاعل المستخدمين إلى BigQuery و Redis ونظام خارجي

مشروع هندسي لمعالجة بيانات تفاعل المستخدمين بشكل لحظي من قاعدة بيانات PostgreSQL إلى ثلاث وجهات مختلفة:
- BigQuery لتحليل البيانات
- Redis لتفاعلات الزمن الحقيقي
- ونظام خارجي (محاكى)

---

# 🧠 نظرة عامة على مكونات المشروع

### 📦 1. `data_generator`
مولّد بيانات يقوم بإنشاء سجلات تفاعل وهمية ويرسلها مباشرة إلى قاعدة PostgreSQL.

---

### 📦 2. `producer`
- يقرأ الأحداث الجديدة من PostgreSQL
- يُثري البيانات ويربطها بجدول المحتوى
- يرسلها إلى Kafka
- يخزنها في ملفات JSON لأجل BigQuery لاحقًا

> ✳️ تم استخدام `processed_key` لضمان `Exactly-once`، و `last_processed.txt` لحفظ آخر توقيت تمت معالجته.

---

### 📦 3. `consumer`
- يستهلك البيانات من Kafka
- يرسلها إلى Redis + نظام خارجي
- يطبع ترتيب التفاعل وآخر الأجهزة استخدامًا خلال آخر 10 دقائق
- يحسب Latency ويطبعه

---

### 📦 4. `uploader`
يرفع ملفات JSON الناتجة من `producer` إلى BigQuery في حال توفر حساب مفوتر.

---

### ⚙️ 5. `docker-compose.yml`
تهيئة بيئة التشغيل بالكامل عبر Docker.

---

# ▶️ طريقة تشغيل المشروع

## 1. تشغيل البيئة

```bash
docker-compose up --build
```

---

## 2. تشغيل السكربتات

```bash
# توليد البيانات
docker exec -it generator python data_generator.py

# تشغيل الـ Producer
docker exec -it producer python event_processor_producer.py

# تشغيل الـ Consumer
docker exec -it consumer python event_processor_consumer.py

# رفع إلى BigQuery (اختياري)
docker exec -it bigquery python load_to_bigquery.py
```

---

## 3. ملاحظات قبل التشغيل

- تأكد من وضع ملف `bq_key.json` داخل `consumer/` و `uploader/`
- الملف `last_processed.txt` يُستخدم لحفظ آخر حدث تمت معالجته لضمان عدم التكرار.

---

# 🧩 القرارات التصميمية وأسبابها

### 1. تخزين بيانات BigQuery في JSON
لعدم توفر حساب مفوتر، تم تخزين البيانات في ملفات JSON مع مجلد `bigquery_batches`، وتحضير طريقة إرسال مباشر داخل الكود (كمُعلّق) لاستخدامها لاحقًا.

---

### 2. استخدام `last_processed.txt`
لتنفيذ `Exactly-once` بسيط وفعّال، يسمح بإعادة التشغيل من آخر نقطة توقف دون تكرار الأحداث.

---

### 3. Redis وجهة لحظية
يتم استخدام Redis لاستخراج الإحصاءات اللحظية خلال أقل من 5 ثوانٍ.

---

### 4. الفصل بين `producer` و `consumer`
لضمان مرونة أكبر، وسهولة في التوسعة، وفصل معالجة المصدر عن معالجة الوجهات.

---

### 5. Kafka كنظام وسيط
يوفر ترتيب، وسرعة، وإدارة الأحداث بين عدة مستهلكين.

---

### 6. Docker لتشغيل موحّد
يوفر Docker بيئة جاهزة لتشغيل كل المكونات بسهولة دون إعدادات معقدة.